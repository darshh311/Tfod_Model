{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.4.60-cp39-cp39-win_amd64.whl (35.1 MB)\n",
      "Collecting numpy>=1.19.3\n",
      "  Using cached numpy-1.21.4-cp39-cp39-win_amd64.whl (14.0 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.21.4 opencv-python-4.5.4.60\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv\n",
    "import cv2 \n",
    "\n",
    "# Import uuid\n",
    "import uuid\n",
    "\n",
    "# Import Operating System\n",
    "import os\n",
    "\n",
    "# Import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Images to Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Bag']\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'nt':\n",
    "         !mkdir {IMAGES_PATH}\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for Bag\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n",
      "Collecting image 10\n",
      "Collecting image 11\n",
      "Collecting image 12\n",
      "Collecting image 13\n",
      "Collecting image 14\n",
      "Collecting image 15\n",
      "Collecting image 16\n",
      "Collecting image 17\n",
      "Collecting image 18\n",
      "Collecting image 19\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in c:\\darsh\\designproject\\tfodcourse\\tfod\\lib\\site-packages (5.15.6)\n",
      "Requirement already satisfied: lxml in c:\\darsh\\designproject\\tfodcourse\\tfod\\lib\\site-packages (4.6.4)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in c:\\darsh\\designproject\\tfodcourse\\tfod\\lib\\site-packages (from pyqt5) (5.15.2)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in c:\\darsh\\designproject\\tfodcourse\\tfod\\lib\\site-packages (from pyqt5) (12.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyqt5 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow\\labelimg'...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.7a943616-4fc0-11ec-8ed4-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.7a943616-4fc0-11ec-8ed4-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.7bcb2705-4fc0-11ec-94dd-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.7bcb2705-4fc0-11ec-94dd-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.7d022332-4fc0-11ec-8e55-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.7d022332-4fc0-11ec-8e55-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.7e387ad2-4fc0-11ec-af92-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.7e387ad2-4fc0-11ec-af92-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.7f6f8dbe-4fc0-11ec-8c6d-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.7f6f8dbe-4fc0-11ec-8c6d-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.75b4c81c-4fc0-11ec-b48a-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.75b4c81c-4fc0-11ec-b48a-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.76ed6261-4fc0-11ec-9d9b-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.76ed6261-4fc0-11ec-9d9b-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.80a5cdb5-4fc0-11ec-9fa8-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.80a5cdb5-4fc0-11ec-9fa8-d0abd5e3b0a1.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: QT_DEVICE_PIXEL_RATIO is deprecated. Instead use:\n",
      "   QT_AUTO_SCREEN_SCALE_FACTOR to enable platform plugin controlled per-screen factors.\n",
      "   QT_SCREEN_SCALE_FACTORS to set per-screen DPI.\n",
      "   QT_SCALE_FACTOR to set the application global scale factor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.81dd1b5e-4fc0-11ec-ba03-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.81dd1b5e-4fc0-11ec-ba03-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.747c2d79-4fc0-11ec-8121-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.747c2d79-4fc0-11ec-8121-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.795c8eaa-4fc0-11ec-973c-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.795c8eaa-4fc0-11ec-973c-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.8449fb3b-4fc0-11ec-b2b1-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.8449fb3b-4fc0-11ec-b2b1-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.734389bd-4fc0-11ec-b4e2-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.734389bd-4fc0-11ec-b4e2-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Darsh\\Darsh.7825248a-4fc0-11ec-80e2-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Darsh/Darsh.7825248a-4fc0-11ec-80e2-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.d98c8f0e-4fc0-11ec-a75b-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.d98c8f0e-4fc0-11ec-a75b-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.dad21373-4fc0-11ec-ad41-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.dad21373-4fc0-11ec-ad41-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.dc0a4a2a-4fc0-11ec-9b9f-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.dc0a4a2a-4fc0-11ec-9b9f-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.dd40ed88-4fc0-11ec-9c24-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.dd40ed88-4fc0-11ec-9c24-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.de7730ab-4fc0-11ec-8b59-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.de7730ab-4fc0-11ec-8b59-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.dfaf4be0-4fc0-11ec-9a7f-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.dfaf4be0-4fc0-11ec-9a7f-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.e0e5780b-4fc0-11ec-98eb-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.e0e5780b-4fc0-11ec-98eb-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.e5c1ab9d-4fc0-11ec-9cc3-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.e5c1ab9d-4fc0-11ec-9cc3-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.e21db5be-4fc0-11ec-ba50-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.e21db5be-4fc0-11ec-ba50-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.e489d0d9-4fc0-11ec-9e2e-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.e489d0d9-4fc0-11ec-9e2e-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.e968f6dd-4fc0-11ec-a558-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.e968f6dd-4fc0-11ec-a558-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.e3521d0b-4fc0-11ec-9b6b-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.e3521d0b-4fc0-11ec-9b6b-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.e831550c-4fc0-11ec-b2f7-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.e831550c-4fc0-11ec-b2f7-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.ea9e4855-4fc0-11ec-b41e-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.ea9e4855-4fc0-11ec-b41e-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.ebd497ce-4fc0-11ec-8176-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.ebd497ce-4fc0-11ec-8176-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.ed0b39d5-4fc0-11ec-ba02-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.ed0b39d5-4fc0-11ec-ba02-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.ee416622-4fc0-11ec-9b58-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.ee416622-4fc0-11ec-9b58-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.ef795bba-4fc0-11ec-80a5-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.ef795bba-4fc0-11ec-80a5-d0abd5e3b0a1.xml\n",
      "Image:C:\\darsh\\designproject\\TFODCourse\\Tensorflow\\workspace\\images\\collectedimages\\Phone\\Phone.f0af3d44-4fc0-11ec-b900-d0abd5e3b0a1.jpg -> Annotation:C:/darsh/designproject/TFODCourse/Tensorflow/workspace/images/collectedimages/Phone/Phone.f0af3d44-4fc0-11ec-b900-d0abd5e3b0a1.xml\n"
     ]
    }
   ],
   "source": [
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Move them into a Training and Testing Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL - 7. Compress them for Colab Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'orkspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
